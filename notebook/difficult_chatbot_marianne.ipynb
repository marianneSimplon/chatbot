{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6911229e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import string\n",
    "import nltk\n",
    "from nltk import *\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D , Activation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05fcbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/Intent.json\") as train_file:\n",
    "    df= json.load(train_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc17f8",
   "metadata": {},
   "source": [
    "# TOKENIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77c25541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Greeting'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"intents\"][0][\"intent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a82bd075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hola</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hello</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello there</td>\n",
       "      <td>Greeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>Can you prove you have a conscious</td>\n",
       "      <td>SelfAware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>Can you prove you are self-aware please</td>\n",
       "      <td>SelfAware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Can you prove you are self aware please</td>\n",
       "      <td>SelfAware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>Can you prove you have a conscious please</td>\n",
       "      <td>SelfAware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>prove you have a conscious</td>\n",
       "      <td>SelfAware</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        inputs       tags\n",
       "0                                           Hi   Greeting\n",
       "1                                     Hi there   Greeting\n",
       "2                                         Hola   Greeting\n",
       "3                                        Hello   Greeting\n",
       "4                                  Hello there   Greeting\n",
       "..                                         ...        ...\n",
       "138         Can you prove you have a conscious  SelfAware\n",
       "139    Can you prove you are self-aware please  SelfAware\n",
       "140    Can you prove you are self aware please  SelfAware\n",
       "141  Can you prove you have a conscious please  SelfAware\n",
       "142                 prove you have a conscious  SelfAware\n",
       "\n",
       "[143 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags = []\n",
    "inputs = []\n",
    "responses = {}\n",
    "\n",
    "for intent in df['intents']:\n",
    "    responses[intent['intent']] = intent['responses']\n",
    "    for lines in intent['text']:\n",
    "        inputs.append(lines)\n",
    "        tags.append(intent['intent'])\n",
    "df = pd.DataFrame({'inputs': inputs, 'tags': tags})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a2c282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"inputs\"] = df[\"inputs\"].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
    "df[\"inputs\"] = df[\"inputs\"].apply(lambda wrd:\"\".join(wrd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e6774370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer les data\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(df[\"inputs\"])\n",
    "train = tokenizer.texts_to_sequences(df[\"inputs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36c87185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply padding\n",
    "x_train = pad_sequences(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15abe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding the outputs\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59e1333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74f88bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words : 117\n",
      "output length  22\n"
     ]
    }
   ],
   "source": [
    "#define vocabulary\n",
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words :\",vocabulary)\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length \", output_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cf2c80",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d18c7752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0202f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocabulary+1,10))\n",
    "model.add(InputLayer(input_shape=(input_shape,)))\n",
    "model.add(SimpleRNN(30))\n",
    "model.add(Dense(output_length, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b0dc76d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f116cd49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 4ms/step - loss: 3.1063 - accuracy: 0.0629\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0806 - accuracy: 0.0979\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0614 - accuracy: 0.1608\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0424 - accuracy: 0.2168\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 3.0230 - accuracy: 0.2517\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 3.0005 - accuracy: 0.2727\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.9755 - accuracy: 0.2797\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9467 - accuracy: 0.3077\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.9113 - accuracy: 0.3427\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.8728 - accuracy: 0.3357\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.8236 - accuracy: 0.3427\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7694 - accuracy: 0.3147\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.7151 - accuracy: 0.3217\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.6581 - accuracy: 0.3217\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5999 - accuracy: 0.3566\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.5397 - accuracy: 0.3217\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4787 - accuracy: 0.3357\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.4265 - accuracy: 0.3706\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 2.3591 - accuracy: 0.3916\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2974 - accuracy: 0.3706\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.2352 - accuracy: 0.4056\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1709 - accuracy: 0.4196\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 2.1139 - accuracy: 0.4755\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 2.0547 - accuracy: 0.4965\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9966 - accuracy: 0.5315\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.9307 - accuracy: 0.5524\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.8734 - accuracy: 0.6084\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.8208 - accuracy: 0.6294\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.7728 - accuracy: 0.6434\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.7193 - accuracy: 0.6364\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.6663 - accuracy: 0.6643\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.6264 - accuracy: 0.6923\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5823 - accuracy: 0.7133\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.5382 - accuracy: 0.6993\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.4892 - accuracy: 0.7063\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4554 - accuracy: 0.7133\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.4120 - accuracy: 0.7273\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3725 - accuracy: 0.7203\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3508 - accuracy: 0.7692\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.3199 - accuracy: 0.7483\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2985 - accuracy: 0.7413\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2572 - accuracy: 0.7343\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.2142 - accuracy: 0.8252\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1885 - accuracy: 0.7762\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1481 - accuracy: 0.7972\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.1251 - accuracy: 0.8042\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.1025 - accuracy: 0.7972\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0824 - accuracy: 0.7902\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 1.0625 - accuracy: 0.8112\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 1.0318 - accuracy: 0.8182\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9962 - accuracy: 0.8252\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9717 - accuracy: 0.8462\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9442 - accuracy: 0.8811\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.9157 - accuracy: 0.8671\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.9021 - accuracy: 0.8811\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8754 - accuracy: 0.8951\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.8613 - accuracy: 0.8811\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8367 - accuracy: 0.9021\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.8291 - accuracy: 0.8951\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7939 - accuracy: 0.8951\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7812 - accuracy: 0.8811\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7740 - accuracy: 0.9441\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7454 - accuracy: 0.9161\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.9231\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.7111 - accuracy: 0.9371\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6923 - accuracy: 0.9441\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6794 - accuracy: 0.9441\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6627 - accuracy: 0.9161\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.6502 - accuracy: 0.9510\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.6318 - accuracy: 0.9441\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6272 - accuracy: 0.9371\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.6291 - accuracy: 0.9161\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5972 - accuracy: 0.9510\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 0.5894 - accuracy: 0.9510\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5772 - accuracy: 0.9441\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5690 - accuracy: 0.9580\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5487 - accuracy: 0.9720\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.5300 - accuracy: 0.9720\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5203 - accuracy: 0.9720\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.9720\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.9720\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.9650\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4805 - accuracy: 0.9720\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.9650\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.9720\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.9720\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.9650\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.9720\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - ETA: 0s - loss: 0.4985 - accuracy: 0.96 - 0s 4ms/step - loss: 0.4142 - accuracy: 0.9720\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.4046 - accuracy: 0.9720\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.9650\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3870 - accuracy: 0.9720\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 0.3774 - accuracy: 0.9720\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3763 - accuracy: 0.9720\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3670 - accuracy: 0.9720\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.9790\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3545 - accuracy: 0.9860\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3584 - accuracy: 0.9720\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3498 - accuracy: 0.9860\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 0.3431 - accuracy: 0.9720\n"
     ]
    }
   ],
   "source": [
    "train = model.fit(x_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25046bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x17d09606fa0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting model accuracy\n",
    "plt.plot(train.history['accuracy'], label=\"training set accuracy\")\n",
    "plt.plot(train.history[\"loss\"], label =\"training set loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a0d76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatting\n",
    "\n",
    "while True:\n",
    "    texts_p = []\n",
    "    prediction_input = input(\"You : \")\n",
    "    \n",
    "    #removing punctuation and converting to lowercase\n",
    "    prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
    "    prediction_input = \"\".join(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    \n",
    "    #tokenizing and padding\n",
    "    prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "    prediction_input = np.array(prediction_input).reshape(-1)\n",
    "    prediction_input = pad_sequences([prediction_input],input_shape)\n",
    "    \n",
    "    #getting output from model\n",
    "    output = model.predict(prediction_input)\n",
    "    output = output.argmax()\n",
    "    \n",
    "    #finding the right tag and predicting\n",
    "    response_tag = le.inverse_transform([output])[0]\n",
    "    print(\"Bot :\",random.choice(responses[response_tag]))\n",
    "    if response_tag == \"goodbye\" :\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd892754",
   "metadata": {},
   "source": [
    "# DELETE OR ADD STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8294ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1e414c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e3a2bb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "74dc712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_words)\n",
    "#this will show all the default stop word in the language english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f81b4ded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'work']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words.append(\"work\")\n",
    "stop_words\n",
    "#this will add or remove a stop word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98c9976",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cad075a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c5784c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmers = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e1ba9e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"i don't know what i am doing please help\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0cdc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = nltk.word_tokenize(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37e2d734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i\n",
      "do\n",
      "n't\n",
      "know\n",
      "what\n",
      "i\n",
      "am\n",
      "do\n",
      "pleas\n",
      "help\n"
     ]
    }
   ],
   "source": [
    "for word in input_str :\n",
    "    print(stemmers.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c4bafa",
   "metadata": {},
   "source": [
    "# LEMMATIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85a70e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d51e46e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "07531ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"so is it the same than stemming\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1203355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = nltk.word_tokenize(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3d157d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so\n",
      "is\n",
      "it\n",
      "the\n",
      "same\n",
      "than\n",
      "stemming\n"
     ]
    }
   ],
   "source": [
    "for word in input_str :\n",
    "    print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e661c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d99cfd7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-0de4263b3477>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mfilter_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Title\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "for index,row in data.iterrows():\n",
    "    filter_sentence = []\n",
    "    sentence = row[\"Title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddf1987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe8cae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Sequential Model\n",
    "model = Sequential() \n",
    "#Create input layer\n",
    "model.add(Dense(32, input_dim=784))\n",
    "#Create hidden layer \n",
    "model.add(Activation('relu')) \n",
    "#Create Output layer\n",
    "model.add(Activation('sigmoid')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b0b4e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model with a mean squared error loss and RMSProp #optimizer\n",
    "model.compile(optimizer='rmsprop',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b12aea83",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'str'>\"}), (<class 'list'> containing values of types set())",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-ebe8c8db0f48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1132\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1133\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1134\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1135\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    974\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    977\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: (<class 'list'> containing values of types {\"<class 'str'>\"}), (<class 'list'> containing values of types set())"
     ]
    }
   ],
   "source": [
    "model.fit(input_str, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7e4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_enc = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07da7425",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (3725, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c5350a34a4dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabel_enc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_label.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m--> 100\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    865\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (3725, 2) instead."
     ]
    }
   ],
   "source": [
    "label_enc.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eccdb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
